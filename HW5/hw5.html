<!DOCTYPE html>
<html lang="en">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <meta name="generator" content="AsciiDoc 8.6.9">
      <title>HCI/CprE/ComS 575: Homework #5</title>
      <link rel="stylesheet" href="./riak.css" type="text/css">
   </head>

   <body class="article">
      <div id="header">
         <h1>HCI/CprE/ComS 575: Homework #5</h1>
         <!-- MAKE CHANGES HERE: Student information -->
         <span id="author">Dawood Ghauri</span><br>
         <span id="email" class="monospaced">&lt;
         <a href="mailto:dghauri@iastate.edu">Email</a>&gt;</span><br>
         <!-- END CHANGES -->
      </div>

      <div id="content">

	  <div id="preamble">
				<div class="sectionbody">
					<div class="paragraph">
						<p>
              The following libraries and references may be useful for solving this homework.
						<ul>
							<li class="level1">
								<div class="li"><a href="https://github.com/sukhoy/nanohmm"
                  class="urlextern" title="https://github.com/sukhoy/nanohmm"
                   rel="nofollow"> NanoHMM library</a> (includes both C and Python implementations).</div>
							</li>
              <li class="level1">
                <div class="li">
                  A tutorial on HMMs:
                  <a href="https://www.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/tutorial%20on%20hmm%20and%20applications.pdf" class="urlextern" title="Tutorial on HMMs" rel="nofollow">
                  paper</a> and <a href="http://alumni.media.mit.edu/~rahimi/rabiner/rabiner-errata/rabiner-errata.html" class="urlextern" title="errata">errata</a>.
                </div>
              </li>
              <li>
                <div class="li">
                  <a href="https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm" class="urlextern" title="Forward-backward algorithm" rel="nofollow">
                  The Wikipedia article on the Forward-Backward algorithm.
                </a>
                </div>
              </li>
            </ul>
					</div>
				</div>
		</div>
		<hr>
		<br>

	     <!-- PART 1 -->
       <div class="sect1">
            <h2 id="_part_1">Part 1: Slow Forward Algorithm</h2>
            <div class="sectionbody">
               <div class="paragraph">
                  <p>Implement the &quot;slow&quot; version of the forward algorithm.
                    It should run in O(N<sup>T</sup>). It should support at least 4 states and sequences of length at least 5.
                    This should be your own code, i.e., you are not allowed to use any other libraries or implementations for this part.
                  </p>
                  <p> In other words, your code needs to compute the  long expression for L (see the example from the lecture for N=2 and T=3).
                  </p>
                  <p> Hint: Think of multiple nested for loops to enumerate all possible state sequences. Alternatively, you can use recursion. If you are writing this in Python, consider using the itertools module that can simplify things for the programmer for tasks like this.
               </div>
			   <div class="listingblock">
                  <div class="title">Source</div>
                  <div class="content monospaced">
                     <pre>
// Insert your code here
					 </pre>
                  </div>
               </div>
</div>
</div>
		<hr>
		<br>


    <!-- PART 2 -->
         <div class="sect2">
            <h2 id="_part_2">Part 2: The Forward Algorithm</h2>
            <div class="sectionbody">
               <div class="paragraph">
                  <p>
                    Implement the Forward algorithm that runs in O(N<sup>2</sup>T).
                    It should support sequences of length at least 8 with at least 5 states. Because these numbers are relatively
                    small, your code doesn't have to re-normalize the probabilities at each step of the algorithm.
                    This should be your own code, i.e., you are not allowed to use any other libraries or implementations for this part.
                  </p>
               </div>
			   <div class="listingblock">
                  <div class="title">Source</div>
                  <div class="content monospaced">
                     <pre>
# From lecture as check
A_ex = [[0.5, 0.5],
        [0, 1]]
B_ex = [[0.5, 0.0, 0.5],
        [0, 1, 0]]
pi_ex = [1, 0]
O_ex = [0, 2, 1]

# HMM model parameters given from 3A
A_3a = [[0.66, 0.34],
        [1, 0]]
B_3a = [[0.5, 0.25, 0.25],
        [0.1, 0.1, 0.8]]
pi_3a = [0.8, 0.2]

# HMM model parameters given from 3B
A_3b = [[0.8, 0.1, 0.1],
        [0.4, 0.2, 0.4],
        [0, 0.3, 0.7]]
B_3b = [[0.66, 0.34, 0],
        [0, 0, 1],
        [0.5, 0.4, 0.1]]
pi_3b = [0.6, 0, 0.4]

O_3 = [0, 1, 0, 2, 0, 1, 0]


def forward_algorithm(A, B, pi, O):
    forward_variable_array = [[0] * len(O) for i in range(len(pi))]
    for time in range(len(O)):
        for state in range(len(pi)):
            if time == 0:
                forward_variable_array[state][time] = pi[state] * B[state][O[time]]
            else:
                for i in range(len(pi)):
                    forward_variable_array[state][time] += forward_variable_array[i][time - 1] * A[i][state] * B[state][
                        O[time]]

    return forward_variable_array


print(forward_algorithm(A_3a, B_3a, pi_3a, O_3))
print(forward_algorithm(A_3b, B_3b, pi_3b, O_3))

					 </pre>
                  </div>
               </div>
</div>
</div>
		<hr>
		<br>


    <!-- PART 3 -->
    <div class="sect3">
       <h2 id="_part_3">Part 3: Forward Check</h2>
       <div class="sectionbody">
          <div class="paragraph">
             <p>
               Check your implementation of the forward algorithm by computing the forward variable alpha for
               the observation sequence O=(0,1,0,2,0,1,0) given the HMM.
             </p>
          </div>
          <div class="paragraph">
            <h3 id="_part_3a">Part 3A: Forward Check Using HMM with Two States</h3>
            <p>The HMM for Part 3A is specified below:
            <pre>
A = [[0.66, 0.34],
     [1, 0]]
B = [[0.5, 0.25, 0.25],
     [0.1, 0.1, 0.8]]
pi = [0.8, 0.2]
            </pre>
          </div>
          <div class="listingblock">
                   <div class="title">Result</div>
                   <div class="content monospaced">
                      <pre>
[[0.4, 0.07100000000000001, 0.030230000000000003, 0.00559145, 0.005956458500000001, 0.0010303429775000003, 0.00044127297707500016],
 [0.020000000000000004, 0.013600000000000001, 0.0024140000000000008, 0.008222560000000002, 0.00019010930000000004, 0.00020251958900000005, 3.503166123500001e-05]]
            </pre>
                   </div>
                </div>
          <div class="paragraph">
            <h3 id="_part_3b">Part 3B: Forward Check Using HMM with Three States</h3>
            <p>The HMM for Part 3B is specified below:
            <pre>
A = [[0.8, 0.1, 0.1],
     [0.4, 0.2, 0.4],
     [0, 0.3, 0.7]]
B = [[0.66, 0.34, 0],
     [0, 0, 1],
     [0.5, 0.4, 0.1]]
pi = [0.6, 0, 0.4]
            </pre>
          </div>
    <div class="listingblock">
             <div class="title">Result</div>
             <div class="content monospaced">
                <pre>
[[0.396, 0.10771200000000002, 0.05687193600000001, 0.0, 0.003919363430400001, 0.0010660668530688003, 0.0005628832984203267],
 [0, 0.0, 0.0, 0.0148460736, 0.0, 0.0, 0.0],
 [0.2, 0.07184, 0.0305296, 0.0027057913600000002, 0.003916241696, 0.0012533222120960001, 0.00049196611688704]]

      </pre>
             </div>
          </div>
</div>
</div>
<hr>
<br>

        <!-- PART 4 -->
		<div class="sect4">
            <h2 id="_part_4">Part 4: The Backward Algorithm</h2>
            <div class="sectionbody">
                <div class="paragraph">
                  <p>Implement the Backward algorithm that runs in O(N<sup>2</sup>T).
                    It should support sequences of length at least 8 with at least 5 states. Because these numbers are relatively
                    small, your code doesn't have to re-normalize the probabilities at each step of the algorithm.
                    This should be your own code, i.e., you are not allowed to use any other libraries or implementations for this part.
				  </p>
                </div>
                <div class="listingblock">
                         <div class="title">Source</div>
                         <div class="content monospaced">
                            <pre>
import math, part2_forward_algorithm

# From lecture as check
A_ex = [[0.5, 0.5],
        [0, 1]]
B_ex = [[0.5, 0.0, 0.5],
        [0, 1, 0]]
pi_ex = [1, 0]
O_ex = [0, 2, 1]


def backward_algorithm(A, B, pi, O):
    backward_variable_array = [[0] * len(O) for i in range(len(pi))]
    forward_variable_array = part2_forward_algorithm.forward_algorithm(A, B, pi, O)
    for time in reversed(range(len(O))):
        for state in range(len(pi)):
            if time == (len(O) - 1):
                # initialization
                backward_variable_array[state][time] = 1
            else:
                for i in range(len(pi)):
                    backward_variable_array[state][time] += A[state][i] * B[i][O[time + 1]] * \
                                                            backward_variable_array[i][time + 1]

    return backward_variable_array


       					 </pre>
                         </div>
                      </div>
             </div>
  </div>
  <hr>
  <br>

  <!-- PART 5 -->
  <div class="sect5">
     <h2 id="_part_5">Part 5: Backward Check</h2>
     <div class="sectionbody">
        <div class="paragraph">
           <p>Check your implementation of the backward algorithm by computing the backward variable beta for
           the observation sequence O=(0,1,0,2,0,1,0) given the HMM.
           </p>
        </div>
        <div class="paragraph">
          <h3 id="_part_5a">Part 5A: Backward Check Using HMM with Two States</h3>
          <p>The HMM for Part 5A is specified below:
          <pre>
A = [[0.66, 0.34],
     [1, 0]]
B = [[0.5, 0.25, 0.25],
     [0.1, 0.1, 0.8]]
pi = [0.8, 0.2]
          </pre>
        </div>
        <div class="listingblock">
                 <div class="title">Result</div>
                 <div class="content monospaced">
                    <pre>
[[0.0011250862706500002, 0.005254026010000001, 0.015186587000000001, 0.028523800000000002, 0.07706, 0.364, 1],
 [0.0013135065025000003, 0.007593293500000001, 0.0071309500000000005, 0.03853, 0.091, 0.5, 1]]

          </pre>
                 </div>
              </div>
        <div class="paragraph">
          <h3 id="_part_5b">Part 5B: Backward Check Using HMM with Three States</h3>
          <p>The HMM for Part 5B is specified below:
          <pre>
A = [[0.8, 0.1, 0.1],
     [0.4, 0.2, 0.4],
     [0, 0.3, 0.7]]
B = [[0.66, 0.34, 0],
     [0, 0, 1],
     [0.5, 0.4, 0.1]]
pi = [0.6, 0, 0.4]
          </pre>
        </div>
  <div class="listingblock">
           <div class="title">Result</div>
           <div class="content monospaced">
              <pre>
[[0.0015827267529984006, 0.004694663427200001, 0.006823102400000002, 0.09530204800000003, 0.17121600000000003, 0.5780000000000001, 1],
 [0.0018615874292992004, 0.006169560473600001, 0.014332204800000003, 0.06480102400000001, 0.134608, 0.464, 1],
 [0.0021404481056, 0.007644457520000001, 0.021841307200000003, 0.0343, 0.09799999999999999, 0.35, 1]]

    </pre>
           </div>
        </div>
</div>
</div>
<hr>
<br>


<!-- PART 6 -->
<div class="sect6">
   <h2 id="_part_6">Part 6: Likelihood Calculation</h2>
   <div class="sectionbody">
      <div class="paragraph">
         <p>Compute the likelihood for each of the following five observation sequences given the same HMM model:
<pre>
O1 = (1,0,0,0,1,0,1)
O2 = (0,0,0,1,1,2,0)
O3 = (1,1,0,1,0,1,2)
O4 = (0,1,0,2,0,1,0)
O5 = (2,2,0,1,1,0,1)
</pre></p>
<p>The HMM for Part 6 is specified below:
<pre>
A = [[0.6, 0.4],
     [1, 0]]
B = [[0.7, 0.3, 0],
     [0.1, 0.1, 0.8]]
pi = [0.7, 0.3]
</pre></p>
<div class="paragraph"><p>
Hint: Compute this by adding the elements in the last column of the alpha array that is computed by your Forward algorithm.
</p></div></div>
<div class="listingblock">
         <div class="title">Result</div>
         <div class="content monospaced">
            <pre>
// Insert the computed likelihood for each sequence here.

Likelihood for O1 = 0.0006833869593599999
Likelihood for O2 = 0.0011935666175999994
Likelihood for O3 = 0.00018577575936
Likelihood for O4 = 0.001353738444799999
Likelihood for O5 = 0.0
  </pre>
         </div>
      </div>
</div>
</div>
<hr>
<br>


<!-- PART 7 -->
<div class="sect7">
   <h2 id="_part_7">Part 7: Likelihood Verification</h2>
   <div class="sectionbody">
      <div class="paragraph">
         <p>
           Verify your implementations of the Forward algorithm and the Backward algorithm
           by computing the likelihood of the observation sequence in multiple ways.
           More specifically, show that the likelihood value can be computed by
           performing the dot product between the corresponding column of the
          forward array and the backward array for each t using the following HMM:
           <pre>
A = [[0.6, 0.4],
     [1, 0]]
B = [[0.7, 0.3, 0],
     [0.1, 0.1, 0.8]]
pi = [0.7, 0.3]
</pre></p>
<p>The observation sequences are:
<pre>
O1 = (1,0,0,0,1,0,1)
O2 = (0,0,0,1,1,2,0)
O3 = (1,1,0,1,0,1,2)
O4 = (0,1,0,2,0,1,0)
O5 = (2,2,0,1,1,0,1)
</pre></p></div>
<div class="listingblock">
         <div class="title">Result</div>
         <div class="content monospaced">
            <pre>
    t=1                       t=2   t=3   t=4   t=5   t=6   t=7
O1  L=0.0006833869593         ...
O2  L=0.001193566617599999    ...
O3  L=0.00018577575936        ...
O4  L=0.001353738444799999    ...
O5  L=0.0                     ...

All likelihood calculations match as expected. For brevity and readability, I've added "..." to show this. Below is each specific output for a given time-stamp.   

Observation Sequence  0 :
Alpha N-by-T array:  [[0.21, 0.10919999999999999, 0.051744, 0.02479008, 0.005083142399999999, 0.0028290420479999993, 0.00057022527744],
                      [0.03, 0.008400000000000001, 0.0043679999999999995, 0.00206976, 0.0009916032, 0.000203325696, 0.00011316168191999998]]
Beta N-by-T array:  [[0.002691587136, 0.0056263648, 0.01173264, 0.024952000000000002, 0.10439999999999999, 0.22, 1],
                     [0.00393845536, 0.008212848, 0.0174664, 0.031319999999999994, 0.154, 0.3, 1]]
Dot product time-step  0 : 0.00068338695936
Dot product time-step  1 : 0.00068338695936
Dot product time-step  2 : 0.00068338695936
Dot product time-step  3 : 0.00068338695936
Dot product time-step  4 : 0.0006833869593599999
Dot product time-step  5 : 0.0006833869593599999
Dot product time-step  6 : 0.0006833869593599999

Observation Sequence  1 :
Alpha N-by-T array:  [[0.48999999999999994, 0.22679999999999992, 0.10897599999999996, 0.02233727999999999, 0.005328422399999998, 0.0, 0.0011935666175999994],
                      [0.03, 0.0196, 0.009071999999999997, 0.004359039999999999, 0.0008934911999999997, 0.0017050951679999993, 0.0]]
Beta N-by-T array:  [[0.00223609344, 0.004660992, 0.0099456, 0.04032, 0.22400000000000003, 0.45999999999999996, 1],
                     [0.0032626943999999997, 0.00696192, 0.012096, 0.06720000000000001, 0.0, 0.7, 1]]
Dot product time-step  0 : 0.0011935666175999999
Dot product time-step  1 : 0.0011935666175999996
Dot product time-step  2 : 0.0011935666175999996
Dot product time-step  3 : 0.0011935666175999996
Dot product time-step  4 : 0.0011935666175999996
Dot product time-step  5 : 0.0011935666175999994
Dot product time-step  6 : 0.0011935666175999994

Observation Sequence  2 :
Alpha N-by-T array:  [[0.21, 0.0468, 0.025536, 0.00515808, 0.0028814016, 0.000580549248, 0.0],
                      [0.03, 0.008400000000000001, 0.0018720000000000002, 0.00102144, 0.0002063232, 0.00011525606400000001, 0.00018577575936]]
Beta N-by-T array:  [[0.0007503759360000003, 0.003132979200000001, 0.006658560000000003, 0.02803200000000001, 0.05760000000000001, 0.32000000000000006, 1],
                     [0.0009398937600000002, 0.004660992000000002, 0.008409600000000001, 0.04032000000000001, 0.09600000000000002, 0.0, 1]]
Dot product time-step  0 : 0.00018577575936000007
Dot product time-step  1 : 0.00018577575936000007
Dot product time-step  2 : 0.00018577575936000007
Dot product time-step  3 : 0.00018577575936000004
Dot product time-step  4 : 0.00018577575936000004
Dot product time-step  5 : 0.00018577575936
Dot product time-step  6 : 0.00018577575936

Observation Sequence  3 :
Alpha N-by-T array:  [[0.48999999999999994, 0.09719999999999997, 0.054543999999999974, 0.0, 0.012217855999999994, 0.0021992140799999985, 0.001265769881599999],
                      [0.03, 0.0196, 0.003887999999999999, 0.017454079999999993, 0.0, 0.0004887142399999998, 8.796856319999995e-05]]
Beta N-by-T array:  [[0.0025712691199999997, 0.010424063999999999, 0.024819199999999996, 0.05205599999999999, 0.11079999999999998, 0.45999999999999996, 1],
                     [0.0031272191999999993, 0.017373439999999997, 0.0, 0.07755999999999998, 0.13799999999999998, 0.7, 1]]
Dot product time-step  0 : 0.0013537384447999995
Dot product time-step  1 : 0.0013537384447999993
Dot product time-step  2 : 0.001353738444799999
Dot product time-step  3 : 0.001353738444799999
Dot product time-step  4 : 0.001353738444799999
Dot product time-step  5 : 0.001353738444799999
Dot product time-step  6 : 0.001353738444799999

Observation Sequence  4 :
Alpha N-by-T array:  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
                      [0.24, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]
Beta N-by-T array:  [[0.00128669184, 0.0027119711999999997, 0.00574416, 0.024952000000000002, 0.10439999999999999, 0.22, 1],
                     [0.0, 0.004020912, 0.0074856, 0.031319999999999994, 0.154, 0.3, 1]]
Dot product time-step  0 : 0.0
Dot product time-step  1 : 0.0
Dot product time-step  2 : 0.0
Dot product time-step  3 : 0.0
Dot product time-step  4 : 0.0
Dot product time-step  5 : 0.0
Dot product time-step  6 : 0.0
  </pre>
         </div>
      </div>
<div class="listingblock">
               <div class="title">Code</div>
               <div class="content monospaced">
                  <pre>
import part2_forward_algorithm
import part4_backward_algorithm

# From lecture as check
A_ex = [[0.5, 0.5],
        [0, 1]]
B_ex = [[0.5, 0.0, 0.5],
        [0, 1, 0]]
pi_ex = [1, 0]
O_ex = [0, 2, 1]

# Given HMM
A = [[0.6, 0.4],
     [1, 0]]
B = [[0.7, 0.3, 0],
     [0.1, 0.1, 0.8]]
pi = [0.7, 0.3]

# Observation Sequences
O = [[1, 0, 0, 0, 1, 0, 1],
     [0, 0, 0, 1, 1, 2, 0],
     [1, 1, 0, 1, 0, 1, 2],
     [0, 1, 0, 2, 0, 1, 0],
     [2, 2, 0, 1, 1, 0, 1]]

alpha_ex = part2_forward_algorithm.forward_algorithm(A_ex, B_ex, pi_ex, O_ex)
beta_ex = part4_backward_algorithm.backward_algorithm(A_ex, B_ex, pi_ex, O_ex)

print(alpha_ex)
print(beta_ex)

print("states: ", len(alpha_ex))
print("times: ", len(O_ex))

for o_s in range(5):
    alpha = part2_forward_algorithm.forward_algorithm(A, B, pi, O[o_s])
    beta = part4_backward_algorithm.backward_algorithm(A, B, pi, O[o_s])

    print("Observation Sequence ", o_s, ":")
    print("Alpha N-by-T array: ", alpha)
    print("Beta N-by-T array: ", beta)
    for time in range(len(O[o_s])):
        L = 0
        for state in range(len(alpha_ex)):
            L += alpha[state][time] * beta[state][time]
        print("Dot product time-step ", time, ":", L)
    print()

        </pre>
               </div>
            </div>
</div>
</div>
<hr>
<br>

<!-- PART 8 -->
<div class="sect8">
   <h2 id="_part_8">Part 8: Match Sequences to HMMs</h2>
   <div class="sectionbody">
      <div class="paragraph">
         <p>Use your implementation of the Forward algorithm to compute the
            likelihood for each of the following five observation sequences given each
            of the following five HMMs. Fill the table below and indicate with *
            the most probable HMM for each sequence.
          </p>
        <p>The observation sequences are:
<pre>
O1 = (1,0,0,0,1,0,1)
O2 = (0,0,0,1,1,2,0)
O3 = (1,1,0,1,0,1,2)
O4 = (0,1,0,2,0,1,0)
O5 = (2,2,0,1,1,0,1)
</pre></p>
<p>The HMMs are:
<pre>
HMM 1:
A =  [[1.0, 0.0], [0.5, 0.5]]
B =  [[0.4, 0.6, 0.0], [0.0, 0.0, 1.0]]
pi =  [0.0, 1.0]

HMM 2:
A =  [[0.25, 0.75], [1.0, 0.0]]
B =  [[0, 1.0, 0], [0.66, 0.0, 0.34]]
pi =  [1.0, 0.0]

HMM 3:
A =  [[0.0, 1.0], [1.0, 0.0]]
B =  [[1.0, 0.0, 0.0], [0.0, 0.66, 0.34]]
pi =  [1.0, 0.0]

HMM 4:
A =  [[1, 0], [0.44, 0.56]]
B =  [[0.36, 0.42, 0.22], [1.0, 0, 0]]
pi =  [0, 1.0]

HMM 5:
A =  [[0.0, 1.0], [1.0, 0.0]]
B =  [[0.25, 0.75, 0.0], [1.0, 0.0, 0.0]]
pi =  [1.0, 0.0]
</pre>
</p>
      </div>
<div class="listingblock">
         <div class="title">Result</div>
         <div class="content monospaced">
            <pre>
    HMM1       HMM2             HMM3        HMM4                     HMM5
O1  L=0.0      L=0.0            L=0.0       L=0.0                   *L=0.10546875
O2  L=0.0      L=0.0            L=0.0      *L=0.00396370630656       L=0.0
O3  L=0.0     *L=0.01562034375  L=0.0       L=0.0                    L=0.0
O4  L=0.0      L=0.0           *L=0.148104  L=0.0007966754611199998  L=0.0
O5 *L=0.00864  L=0.0            L=0.0       L=0.0                    L=0.0
  </pre>
         </div>
      </div>
<div class="listingblock">
       <div class="title">Code</div>
           <div class="content monospaced">
    <pre>
import part2_forward_algorithm

# From lecture as check
A_ex = [[0.5, 0.5],
        [0, 1]]
B_ex = [[0.5, 0.0, 0.5],
        [0, 1, 0]]
pi_ex = [1, 0]
O_ex = [0, 2, 1]

# HMM 1:
A_1 = [[1.0, 0.0], [0.5, 0.5]]
B_1 = [[0.4, 0.6, 0.0], [0.0, 0.0, 1.0]]
pi_1 = [0.0, 1.0]

# HMM 2:
A_2 = [[0.25, 0.75], [1.0, 0.0]]
B_2 = [[0, 1.0, 0], [0.66, 0.0, 0.34]]
pi_2 = [1.0, 0.0]

# HMM 3:
A_3 = [[0.0, 1.0], [1.0, 0.0]]
B_3 = [[1.0, 0.0, 0.0], [0.0, 0.66, 0.34]]
pi_3 = [1.0, 0.0]

# HMM 4:
A_4 = [[1, 0], [0.44, 0.56]]
B_4 = [[0.36, 0.42, 0.22], [1.0, 0, 0]]
pi_4 = [0, 1.0]

# HMM 5:
A_5 = [[0.0, 1.0], [1.0, 0.0]]
B_5 = [[0.25, 0.75, 0.0], [1.0, 0.0, 0.0]]
pi_5 = [1.0, 0.0]

O = [[1, 0, 0, 0, 1, 0, 1],
     [0, 0, 0, 1, 1, 2, 0],
     [1, 1, 0, 1, 0, 1, 2],
     [0, 1, 0, 2, 0, 1, 0],
     [2, 2, 0, 1, 1, 0, 1]]

alpha = [[None] for i in range(6)]

# Iterate through each observation sequence
for i in range(len(O)):
    print("Observation Sequence ", i)

    # Create all alpha variable N-by-T vectors
    alpha[0] = part2_forward_algorithm.forward_algorithm(A_ex, B_ex, pi_ex, O_ex)
    alpha[1] = part2_forward_algorithm.forward_algorithm(A_1, B_1, pi_1, O[i])
    alpha[2] = part2_forward_algorithm.forward_algorithm(A_2, B_2, pi_2, O[i])
    alpha[3] = part2_forward_algorithm.forward_algorithm(A_3, B_3, pi_3, O[i])
    alpha[4] = part2_forward_algorithm.forward_algorithm(A_4, B_4, pi_4, O[i])
    alpha[5] = part2_forward_algorithm.forward_algorithm(A_5, B_5, pi_5, O[i])

    # Iterate through each alpha associated with each HMM
    count = 0
    for j in range(len(alpha)):
        L = 0

        # Sum last elements of each state
        for states in range(len(alpha[j])):
            L += alpha[j][states][len(alpha[j][states]) - 1]
        print("Likelihood for HMM ", count, ":", L)
        count = count + 1
    print(alpha)
    print()


</pre>
    </div>
    </div>
    </div>
  </div>
<hr>
<br>


<!-- PART 9 -->
<div class="sect9">
   <h2 id="_part_9">Part 9: Match Sequences to HMMs (using <a href="https://github.com/sukhoy/nanohmm" class="urlextern" title="https://github.com/sukhoy/nanohmm" rel="nofollow">NanoHMM</a>)</h2>
   <div class="sectionbody">
      <div class="paragraph">
         <p>
           This problem is similar to Part 8, but the sequences are now longer and
           your Forward and Backward algorithms may no longer work because they
           don't perform renormalization at each step.</p>
        <p>
           Use the implementation of the Forward algorithm in the <a href="https://github.com/sukhoy/nanohmm"
           class="urlextern" title="https://github.com/sukhoy/nanohmm" rel="nofollow">NanoHMM</a> library
           to compute the log-likelihood for each of the following five observation
           sequences given each of the following five HMMs. Fill the table below
           and indicate with * the most likely HMM for each sequence. In all cases,
           N=5, M=6, and T=20.
<pre>
O1 = (4,2,5,1,5,1,5,3,2,3,2,0,1,0,0,4,4,3,0,1)
O2 = (3,2,3,3,5,5,5,5,1,0,1,4,2,4,3,0,5,3,1,0)
O3 = (4,3,0,3,4,0,1,0,2,0,5,3,2,0,0,5,5,3,5,4)
O4 = (3,4,2,0,5,4,4,3,1,5,3,3,2,3,0,4,2,5,2,4)
O5 = (2,0,5,4,4,2,0,5,5,4,4,2,0,5,4,4,5,5,5,5)
</pre></p><p>The HMMs are:
<pre>
HMM 1:
A =  [[0.33, 0, 0, 0.67, 0],
      [0.67, 0, 0.33, 0, 0],
      [0, 1.0, 0.0, 0, 0],
      [0, 0, 0, 0.25, 0.75],
      [0.0, 0.0, 0.6, 0, 0.4]]
B =  [[0.67, 0, 0, 0, 0, 0.33],
      [0.0, 1.0, 0, 0, 0, 0],
      [0.5, 0, 0, 0, 0, 0.5],
      [0, 0, 0, 0.25, 0.75, 0],
      [0, 0.0, 0.6, 0.4, 0, 0.0]]
pi =  [0.0, 0.0, 0.0, 1.0, 0.0]


HMM 2:
A =  [[0.0, 0.0, 1.0, 0, 0.0],
      [0.0, 0, 0.0, 0.0, 1.0],
      [0.38, 0.0, 0.23, 0.38, 0.0],
      [0.0, 0.31, 0.0, 0.69, 0],
      [0.0, 0.75, 0.0, 0.25, 0.0]]
B =  [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
      [0.0, 0.6, 0.2, 0.2, 0.0, 0.0],
      [0.0, 0.0, 0, 1.0, 0.0, 0],
      [0, 0.0, 0, 0.22, 0.0, 0.78],
      [0.6, 0.0, 0.0, 0.0, 0.4, 0.0]]
pi =  [0.0, 0.0, 1.0, 0.0, 0.0]

HMM 3:
A =  [[0, 0.0, 0.32, 0.18, 0.5],
      [0.0, 0.0, 0.0, 1.0, 0.0],
      [0, 0.0, 0, 0.0, 1.0],
      [0, 0.64, 0, 0.0, 0.36],
      [1.0, 0.0, 0, 0, 0]]
B =  [[0.0, 0.17, 0.33, 0.0, 0.0, 0.5],
      [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
      [0.47, 0.0, 0.0, 0.0, 0.0, 0.53],
      [0.27, 0.0, 0.0, 0.0, 0.73, 0.0],
      [0.66, 0.0, 0.0, 0.33, 0.0, 0.0]]
pi =  [0.0, 0.0, 0.0, 1.0, 0.0]

HMM 4:
A =  [[0.0, 0.0, 1.0, 0, 0.0],
      [0.0, 0, 0.62, 0, 0.38],
      [0.0, 0.5, 0.0, 0.5, 0.0],
      [0.0, 0.23, 0.0, 0.0, 0.77],
      [0.0, 0, 0, 1.0, 0]]
B =  [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
      [0.0, 0.0, 0.62, 0, 0.38, 0.0],
      [0, 0.0, 0.0, 0.0, 1, 0],
      [0, 0.0, 0, 0.41, 0.18, 0.41],
      [0.31, 0.16, 0.37, 0.16, 0, 0.0]]
pi =  [1.0, 0.0, 0.0, 0.0, 0]

HMM 5:
A =  [[0.5, 0.33, 0, 0.17, 0.0],
      [0.0, 0.0, 0.0, 0.0, 1.0],
      [0.75, 0.0, 0.25, 0.0, 0.0],
      [0.0, 0.0, 0, 1.0, 0.0],
      [0.0, 0.0, 1.0, 0.0, 0.0]]
B =  [[0.0, 0.0, 0.0, 0.0, 1.0, 0],
      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
      [0.0, 0.0, 0.0, 0.0, 0, 1.0],
      [0.0, 0.0, 0.0, 0.0, 0, 1.0],
      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]]
pi =  [0.0, 1.0, 0.0, 0.0, 0.0]
</pre>
</p>
      </div>
<div class="listingblock">
         <div class="title">Result</div>
         <div class="content monospaced">
            <pre>
     HMM1     	HMM2        HMM3        HMM4        HMM5
O1  *-28.465  	-inf        -inf        -inf        -inf
O2   -inf      *-28.633     -inf        -inf        -inf
O3   -inf       -inf       *-30.973     -inf        -inf
O4   -inf       -inf        -inf       *-34.744     -inf
O5   -inf       -inf        -inf        -inf       *-12.000
  </pre>
         </div>
      </div>
      <div class="listingblock">
             <div class="title">Code</div>
                 <div class="content monospaced">
          <pre>
from __future__ import print_function

import nanohmm

# HMM 1.
A_1 = [[0.33, 0, 0, 0.67, 0],
       [0.67, 0, 0.33, 0, 0],
       [0, 1.0, 0.0, 0, 0],
       [0, 0, 0, 0.25, 0.75],
       [0.0, 0.0, 0.6, 0, 0.4]]
B_1 = [[0.67, 0, 0, 0, 0, 0.33],
       [0.0, 1.0, 0, 0, 0, 0],
       [0.5, 0, 0, 0, 0, 0.5],
       [0, 0, 0, 0.25, 0.75, 0],
       [0, 0.0, 0.6, 0.4, 0, 0.0]]
pi_1 = [0.0, 0.0, 0.0, 1.0, 0.0]

# HMM 2.
A_2 = [[0.0, 0.0, 1.0, 0, 0.0],
       [0.0, 0, 0.0, 0.0, 1.0],
       [0.38, 0.0, 0.23, 0.38, 0.0],
       [0.0, 0.31, 0.0, 0.69, 0],
       [0.0, 0.75, 0.0, 0.25, 0.0]]
B_2 = [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
       [0.0, 0.6, 0.2, 0.2, 0.0, 0.0],
       [0.0, 0.0, 0, 1.0, 0.0, 0],
       [0, 0.0, 0, 0.22, 0.0, 0.78],
       [0.6, 0.0, 0.0, 0.0, 0.4, 0.0]]
pi_2 = [0.0, 0.0, 1.0, 0.0, 0.0]

# HMM 3.
A_3 = [[0, 0.0, 0.32, 0.18, 0.5],
       [0.0, 0.0, 0.0, 1.0, 0.0],
       [0, 0.0, 0, 0.0, 1.0],
       [0, 0.64, 0, 0.0, 0.36],
       [1.0, 0.0, 0, 0, 0]]
B_3 = [[0.0, 0.17, 0.33, 0.0, 0.0, 0.5],
       [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
       [0.47, 0.0, 0.0, 0.0, 0.0, 0.53],
       [0.27, 0.0, 0.0, 0.0, 0.73, 0.0],
       [0.66, 0.0, 0.0, 0.33, 0.0, 0.0]]
pi_3 = [0.0, 0.0, 0.0, 1.0, 0.0]

# HMM 4.
A_4 = [[0.0, 0.0, 1.0, 0, 0.0],
       [0.0, 0, 0.62, 0, 0.38],
       [0.0, 0.5, 0.0, 0.5, 0.0],
       [0.0, 0.23, 0.0, 0.0, 0.77],
       [0.0, 0, 0, 1.0, 0]]
B_4 = [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
       [0.0, 0.0, 0.62, 0, 0.38, 0.0],
       [0, 0.0, 0.0, 0.0, 1, 0],
       [0, 0.0, 0, 0.41, 0.18, 0.41],
       [0.31, 0.16, 0.37, 0.16, 0, 0.0]]
pi_4 = [1.0, 0.0, 0.0, 0.0, 0]

# HMM 5.
A_5 = [[0.5, 0.33, 0, 0.17, 0.0],
       [0.0, 0.0, 0.0, 0.0, 1.0],
       [0.75, 0.0, 0.25, 0.0, 0.0],
       [0.0, 0.0, 0, 1.0, 0.0],
       [0.0, 0.0, 1.0, 0.0, 0.0]]
B_5 = [[0.0, 0.0, 0.0, 0.0, 1.0, 0],
       [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
       [0.0, 0.0, 0.0, 0.0, 0, 1.0],
       [0.0, 0.0, 0.0, 0.0, 0, 1.0],
       [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]]
pi_5 = [0.0, 1.0, 0.0, 0.0, 0.0]

# Given observation sequences.
O_1 = [4, 2, 5, 1, 5, 1, 5, 3, 2, 3, 2, 0, 1, 0, 0, 4, 4, 3, 0, 1]
O_2 = [3, 2, 3, 3, 5, 5, 5, 5, 1, 0, 1, 4, 2, 4, 3, 0, 5, 3, 1, 0]
O_3 = [4, 3, 0, 3, 4, 0, 1, 0, 2, 0, 5, 3, 2, 0, 0, 5, 5, 3, 5, 4]
O_4 = [3, 4, 2, 0, 5, 4, 4, 3, 1, 5, 3, 3, 2, 3, 0, 4, 2, 5, 2, 4]
O_5 = [2, 0, 5, 4, 4, 2, 0, 5, 5, 4, 4, 2, 0, 5, 4, 4, 5, 5, 5, 5]

for i in range(5):
    f = 0.0
    if i == 0:
        lambda_ = nanohmm.hmm_t(A_1, B_1, pi_1)
        f = nanohmm.forward_t(lambda_)

    if i == 1:
        lambda_ = nanohmm.hmm_t(A_2, B_2, pi_2)
        f = nanohmm.forward_t(lambda_)

    if i == 2:
        lambda_ = nanohmm.hmm_t(A_3, B_3, pi_3)
        f = nanohmm.forward_t(lambda_)

    if i == 3:
        lambda_ = nanohmm.hmm_t(A_4, B_4, pi_4)
        f = nanohmm.forward_t(lambda_)

    if i == 4:
        lambda_ = nanohmm.hmm_t(A_5, B_5, pi_5)
        f = nanohmm.forward_t(lambda_)

    print("Computed LL's for HMM ", i + 1, ":")
    print("O1: ", nanohmm.forward(f, O_1))
    print("O2: ", nanohmm.forward(f, O_2))
    print("O3: ", nanohmm.forward(f, O_3))
    print("O4: ", nanohmm.forward(f, O_4))
    print("O5: ", nanohmm.forward(f, O_5))
    print()

# lambda_ = nanohmm.hmm_t(A_1, B_1, pi_1)
# f = nanohmm.forward_t(lambda_)
# print("O2: ", nanohmm.forward(f, O_2))

      </pre>
          </div>
          </div>
</div>
</div>
<hr>
<br>

<!-- PART 10 -->
<div class="sect10">
   <h2 id="_part_10">Part 10: Train HMMs (using the <a href="https://github.com/sukhoy/nanohmm" class="urlextern" title="https://github.com/sukhoy/nanohmm" rel="nofollow">NanoHMM</a> library)</h2>
   <div class="sectionbody">
      <div class="paragraph">
      <p> For part 10, the model lambda=(A,B,pi) is not provided so you need to start with random values and iterate until convergence. Then restart with
         another set of random values and repeat the process. From all models that converged, you need to pick the best one. See the library for an example.
         
        <p>The following five observation sequences are used for both parts 10A and 10B:
<pre>
O1 = (4,2,5,1,5,1,5,3,2,3,2,0,1,0,0,4,4,3,0,1)
O2 = (3,2,3,3,5,5,5,5,1,0,1,4,2,4,3,0,5,3,1,0)
O3 = (4,3,0,3,4,0,1,0,2,0,5,3,2,0,0,5,5,3,5,4)
O4 = (3,4,2,0,5,4,4,3,1,5,3,3,2,3,0,4,2,5,2,4)
O5 = (2,0,5,4,4,2,0,5,5,4,4,2,0,5,4,4,5,5,5,5)
</pre>
         </p>
      </div>
  <h3 id="_part_10a">Part 10A: Train 3-State HMMs</h3>
  <p>
    Train a 3-state HMM for each of the five observation sequences using the Baum-Welch
    implementation in the <a href="https://github.com/sukhoy/nanohmm"
    class="urlextern" title="https://github.com/sukhoy/nanohmm" rel="nofollow">NanoHMM</a> library.</p>
<div class="listingblock">
         <div class="title">Result</div>
         <div class="content monospaced">
            <pre>
Trained HMM for O1:

A = [[1.0337429850610959e-15, 0.2857142857142848, 0.7142857142857142], 
     [0.0, 0.4000000000000001, 0.5999999999999999], 
     [1.0, 2.0709314992881206e-39, 7.669759859085802e-71]]
B = [[0.28571428571428653, 0.0, 0.2857142857142854, 0.0, 0.0, 0.428571428571428],
     [0.39999999999999913, 1.6819391575719872e-46, 0.0, 6.806263697302132e-49, 0.6000000000000009, 0.0],
     [0.0, 0.5, 0.12499999999999997, 0.37500000000000006, 0.0, 0.0]]
pi = [0.0, 1.0, 0.0]
LL = -37.8930593745894


Trained HMM for O2:


A =  [[1.5638856392329388e-87, 0.0, 1.0],
      [1.0, 0.0, 2.8498175789997116e-125], 
      [0.5714285714285714, 0.42857142857142855, 7.707351686583165e-94]]
B =  [[0.125, 0.375, 0.25, 6.076054570114311e-136, 0.0, 0.25],
      [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],
      [0.25, 0.0, 0.0, 0.125, 0.25, 0.375]]
pi =  [0.0, 1.0, 0.0]
LL = -37.38682194791283


Trained HMM for O3:


A =  [[2.1589590690523603e-129, 0.1111111088936615, 0.8888888911063385],
      [1.0, 0.0, 0.0],
      [0.8750000003121619, 0.1249999996878382, 0.0]]
B =  [[0.4444444444443129, 0.0, 0.0, 0.4444444444443129, 2.9596620842659803e-13, 0.11111111111107823],
      [1.655561793645452e-37, 2.024132050313525e-39, 1.279605549929887e-38, 7.802929806212717e-136, 1.0, 3.1615515264627673e-53],
      [0.24999999937634226, 0.12499999968817113, 0.24999999937634226, 0.0, 2.4946308104463328e-09, 0.3749999990645134]]
pi =  [0.0, 1.0, 0.0]
LL = -36.65227807299477


Trained HMM for O4:


A =  [[6.581961407997314e-187, 0.42857142857142855, 0.5714285714285714],
      [0.0, 0.0, 1.0],
      [1.0, 0.0, 9.611506101555518e-159]]
B =  [[0.0, 0.0, 0.25, 0.0, 0.375, 0.375],
      [0.0, 0.0, 9.307552072310879e-58, 1.0, 0.0, 0.0],
      [0.25, 0.125, 0.25, 0.125, 0.25, 0.0]]
pi =  [0.0, 1.0, 0.0]
LL = -37.90247907211473


Trained HMM for O5: (lowest LL yet!)


A =  [[0.0, 0.0, 1.0],
      [1.0, 0.0, 0.0],
      [0.0, 0.15384615384615385, 0.8461538461538461]]
B =  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0],
      [0.0, 0.0, 1.0, 0.0, 0.0, 2.7654654244320435e-182],
      [0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.5714285714285714]]
pi =  [0.0, 1.0, 0.0]
LL = -21.845162435303454

  </pre>
         </div>
      </div>
          <h3 id="_part_10a">Part 10B: Train 4-State HMMs</h3>
          <p>
            Train a 4-state HMM for each of the five observation sequences using the Baum-Welch
            implementation in the <a href="https://github.com/sukhoy/nanohmm"
            class="urlextern" title="https://github.com/sukhoy/nanohmm" rel="nofollow">NanoHMM</a> library.</p>
        <div class="listingblock">
                 <div class="title">Result</div>
                 <div class="content monospaced">
                    <pre>
Trained HMM for O1:


A =  [[0.0, 0.5, 1.5085970058411494e-76, 0.5],
      [0.0, 5.012449753387121e-112, 1.0, 2.2335256404783703e-107],
      [0.8, 0.2, 0.0, 0.0],
      [0.6666666666666666, 0.3333333333333333, 0.0, 0.0]]
B =  [[0.16666666666666669, 0.0, 0.5000000000000001, 0.0, 0.16666666666666669, 0.16666666666666669],
      [0.6, 3.473924275083547e-200, 0.0, 0.0, 0.0, 0.4],
      [0.0, 0.6666666666666666, 0.0, 2.771627214053552e-129, 0.3333333333333333, 0.0],
      [0.0, 7.591243561139011e-50, 0.0, 1.0, 0.0, 0.0]]
pi =  [0.0, 0.0, 1.0, 0.0]
LL = -33.48394345536404


Trained HMM for O2:


A =  [[0.0, 0.25, 4.886846220317961e-201, 0.75],
      [4.97686294924721e-191, 1.2381646701538707e-138, 1.0, 1.0877930653409615e-106],
      [0.0, 0.4738600715901401, 0.19861546805649538, 0.3275244603533645],
      [1.0, 4.37340199752397e-142, 2.493978608109551e-168, 0.0]]
B =  [[0.6, 0.0, 0.0, 0.0, 0.4, 1.68365051870567e-310],
      [0.0, 0.0, 0.25683265739436106, 6.494440680517119e-94, 0.0, 0.7431673426056389],
      [0.0, 0.0, 1.3634623558891624e-248, 0.6550489207067289, 2.7827922562828886e-224, 0.3449510792932712],
      [0.0, 0.6, 0.2, 0.2, 0.0, 0.0]]
pi =  [0.0, 0.0, 1.0, 0.0]
LL = -32.337651181364684


Trained HMM for O3:


A =  [[0.0, 0.7702064782341591, 0.0, 0.22979352176584095],
      [0.0, 0.6666666666666667, 0.0, 0.33333333333333337],
      [1.0, 0.0, 0.0, 0.0],
      [0.7629979943239658, 8.474983436857064e-286, 5.393434939123091e-39, 0.2370020056760342]]
B =  [[0.0, 0.0, 3.434631602623966e-171, 0.5914247759741272, 0.40857522402587276, 7.974566420301658e-203],
      [0.6666666666666666, 0.11111111111111109, 0.22222222222222218, 0.0, 0.0, 2.5787039917826756e-78],
      [0.0, 0.0, 0.0, 0.0, 1.0, 0.0], 
      [6.098340227448281e-108, 0.0, 0.0, 0.21644533585601522, 2.1398140936179698e-160, 0.7835546641439848]]
pi =  [0.0, 0.0, 1.0, 0.0]
LL = -34.48528555100951


Trained HMM for O4:


A =  [[4.087313638361648e-241, 3.444038495674655e-57, 0.42857142857142855, 0.5714285714285714],
      [1.0, 0.0, 0.0, 0.0],
      [0.0, 1.0, 0.0, 8.50120428720881e-57],
      [1.0, 6.564588431052582e-147, 0.0, 3.3971044747791524e-145]]
B =  [[0.0, 0.0, 0.25, 0.0, 0.375, 0.375],
      [0.25, 0.25, 0.0, 0.25, 0.25, 0.0],
      [0.0, 0.0, 3.089515263759211e-113, 1.0, 0.0, 0.0],
      [0.25, 0.0, 0.5, 0.0, 0.25, 0.0]]
pi =  [0.0, 0.0, 1.0, 0.0]
LL = -33.38682194791282


Trained HMM for O5:

A =  [[0.0, 0.0, 0.0, 1.0],
      [0.0, 0.5000000000000001, 0.33333333333333337, 0.16666666666666669],
      [1.0, 0.0, 0.0, 0.0],
      [0.0, 0.42857142857142855, 0.0, 0.5714285714285714]]
B =  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0],
      [0.0, 0.0, 0.0, 0.0, 1.0, 8.393573790177763e-62],
      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],
      [0.0, 0.0, 0.0, 0.0, 7.114914386369923e-48, 1.0]]
pi =  [0.0, 0.0, 1.0, 0.0]
LL = -15.651484454403226

</pre>
                 </div>
              </div>
              <div class="listingblock">
                     <div class="title">Code</div>
                         <div class="content monospaced">
                  <pre>
// 10A Code

from __future__ import print_function

import random

import nanohmm

# A = [[0.5, 0.5], [0.0, 1.0], [0.5, 0.5]]
# B = [[0.5, 0.5, 0.0], [0.5, 0.0, 0.5], [0.0, 0.5, 0.5]]
# pi = [0.0, 0.5, 0.5]

A = [[0.4, 0.0, 0.6],
     [0.2, 0.6, 0.2],
     [0.2, 0.4, 0.4]]
B = [[0.16, 0.0, 0.32, 0.16, 0.16, 0.20],
     [0.16, 0.16, 0.16, 0.16, 0.16, 0.20],
     [0.16, 0.16, 0.16, 0.16, 0.16, 0.20]]
pi = [0.5, 0.5, 0.0]

lambda_ = nanohmm.hmm_t(A, B, pi)
bw = nanohmm.baumwelch_t(lambda_)
O1 = [4, 2, 5, 1, 5, 1, 5, 3, 2, 3, 2, 0, 1, 0, 0, 4, 4, 3, 0, 1]
O2 = [3, 2, 3, 3, 5, 5, 5, 5, 1, 0, 1, 4, 2, 4, 3, 0, 5, 3, 1, 0]
O3 = [4, 3, 0, 3, 4, 0, 1, 0, 2, 0, 5, 3, 2, 0, 0, 5, 5, 3, 5, 4]
O4 = [3, 4, 2, 0, 5, 4, 4, 3, 1, 5, 3, 3, 2, 3, 0, 4, 2, 5, 2, 4]
O5 = [2, 0, 5, 4, 4, 2, 0, 5, 5, 4, 4, 2, 0, 5, 4, 4, 5, 5, 5, 5]
LL, lambda_ = nanohmm.baumwelch(bw, O5, 100)

iterations = 100
target_LL = -30.0
states = 3
M = 6
for i in range(iterations):

    if round(target_LL, 3) == round(LL, 3):
        break
    else:
        for j in range(states):
            prob = random.uniform(0, 1)
            A[j][0] = prob
            A[j][1] = (1 - prob) / 2
            A[j][2] = (1 - prob) / 2
            # print(A[j])
        for j in range(states):
            prob = random.uniform(0, 1)
            for k in range(M):
                B[j][k] = prob
                prob = (1 - prob)  # This doesn't make sense, but it tends to give me the lowest LL score.
            # print(B[j])

    lambda_ = nanohmm.hmm_t(A, B, pi)
    bw = nanohmm.baumwelch_t(lambda_)
    LL, lambda_ = nanohmm.baumwelch(bw, O5, 200)

print("LL =", LL)
print("Trained HMM:")
print("A = ", lambda_.A)
print("B = ", lambda_.B)
print("pi = ", lambda_.pi)


// 10B Code

from __future__ import print_function

import random

import nanohmm

# A = [[0.5, 0.5], [0.0, 1.0], [0.5, 0.5]]
# B = [[0.5, 0.5, 0.0], [0.5, 0.0, 0.5], [0.0, 0.5, 0.5]]
# pi = [0.0, 0.5, 0.5]

A = [[0.4, 0.0, 0.4, 0.2],
     [0.2, 0.4, 0.2, 0.2],
     [0.2, 0.4, 0.3, 0.1],
     [0.6, 0.2, 0.2, 0.0]]
B = [[0.16, 0.0, 0.32, 0.16, 0.16, 0.20],
     [0.16, 0.16, 0.16, 0.16, 0.16, 0.20],
     [0.16, 0.16, 0.16, 0.16, 0.16, 0.20],
     [0.16, 0.16, 0.16, 0.16, 0.16, 0.20]]
pi = [0.2, 0.0, 0.8, 0.0]

lambda_ = nanohmm.hmm_t(A, B, pi)
bw = nanohmm.baumwelch_t(lambda_)
O1 = [4, 2, 5, 1, 5, 1, 5, 3, 2, 3, 2, 0, 1, 0, 0, 4, 4, 3, 0, 1]
O2 = [3, 2, 3, 3, 5, 5, 5, 5, 1, 0, 1, 4, 2, 4, 3, 0, 5, 3, 1, 0]
O3 = [4, 3, 0, 3, 4, 0, 1, 0, 2, 0, 5, 3, 2, 0, 0, 5, 5, 3, 5, 4]
O4 = [3, 4, 2, 0, 5, 4, 4, 3, 1, 5, 3, 3, 2, 3, 0, 4, 2, 5, 2, 4]
O5 = [2, 0, 5, 4, 4, 2, 0, 5, 5, 4, 4, 2, 0, 5, 4, 4, 5, 5, 5, 5]
LL, lambda_ = nanohmm.baumwelch(bw, O1, 100)

iterations = 100
target_LL = -30.0
states = 4
M = 6
for i in range(iterations):

    if round(target_LL, 3) == round(LL, 3):
        break
    else:
        for j in range(states):
            prob = random.uniform(0, 1)
            A[j][0] = prob
            A[j][1] = (1 - prob) / 2
            A[j][2] = (1 - prob) / 2
            A[j][3] = (1 - prob) / 2
            # print(A[j])
        for j in range(states):
            prob = random.uniform(0, 1)
            for k in range(M):
                B[j][k] = prob
                prob = (1 - prob)  # This doesn't make sense, but it tends to give me the lowest LL score.
            # print(B[j])

    lambda_ = nanohmm.hmm_t(A, B, pi)
    bw = nanohmm.baumwelch_t(lambda_)
    LL, lambda_ = nanohmm.baumwelch(bw, O1, 200)

print("LL =", LL)
print("Trained HMM:")
print("A = ", lambda_.A)
print("B = ", lambda_.B)
print("pi = ", lambda_.pi)

              </pre>
                  </div>
                  </div>
        </div>
  </div>
<hr>
<br>
        <h1 id="_ec">Extra Credit</h1>
        <div class="sectionbody">
           <div class="paragraph">
              <p>For each of the three problems below, you are allowed to use only
                your own code. In other words, you are not allowed to use any other
                 libraries or implementations for these problems.
              </p>
           </div>
         </div>
	     <!-- PART EC1 -->
         <div class="sectEC1">
            <h2 id="_part_ec1">Part EC1: Implement the Forward Algorithm with Re-Normalization</h2>
             <div class="listingblock">
                <div class="title">Source</div>
                <div class="content monospaced">
                  <pre>
// Insert your code here
                 </pre>
              </div>
          </div> 
        </div>
			  <br>

        <!-- PART EC2 -->
          <div class="sectEC2">
             <h2 id="_part_ec2">Part EC2: Implement the Forward-Backward Algorithm with Re-Normalization</h2>
             <div class="listingblock">
                <div class="title">Source</div>
                <div class="content monospaced">
                  <pre>
// Insert your code here
                 </pre>
              </div>
          </div>
        </div>
 			  <br>

        <!-- PART EC3 -->
          <div class="sectEC3">
             <h2 id="_part_ec3">Part EC3: Implement the Baum-Welch Algorithm</h2>
             <div class="listingblock">
                <div class="title">Source</div>
                <div class="content monospaced">
                  <pre>
// Insert your code here
                 </pre>
              </div>
          </div>
        </div>
 			  <br>

      <div id="footer">
         <div id="footer-text">
            Last updated 2022-04-07
         </div>
      </div>
    </div>
   </body>
</html>
